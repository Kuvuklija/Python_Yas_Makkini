{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76369670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@ READING TEXT FILE BY BATH @@@@@@@@@@@@@@@@@\n",
    "\n",
    "# output only 10 rows on display\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "result = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex6.csv')\n",
    "result\n",
    "\"\"\"\n",
    "one \ttwo \tthree \tfour \tkey\n",
    "0 \t0.467976 \t-0.038649 \t-0.295344 \t-1.824726 \tL\n",
    "1 \t-0.358893 \t1.404453 \t0.704965 \t-0.200638 \tB\n",
    "2 \t-0.501840 \t0.659254 \t-0.421691 \t-0.057688 \tG\n",
    "3 \t0.204886 \t1.074134 \t1.388361 \t-0.982404 \tR\n",
    "4 \t0.354628 \t-0.133116 \t0.283763 \t-0.837063 \tQ\"\"\"\n",
    "\n",
    "# get first 3 rows\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex6.csv', nrows=3)\n",
    "\"\"\"\n",
    " \tone \ttwo \tthree \tfour \tkey\n",
    "0 \t0.467976 \t-0.038649 \t-0.295344 \t-1.824726 \tL\n",
    "1 \t-0.358893 \t1.404453 \t0.704965 \t-0.200638 \tB\n",
    "2 \t-0.501840 \t0.659254 \t-0.421691 \t-0.057688 \tG\"\"\"\n",
    "\n",
    "# read file by chunkes\n",
    "chunker = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex6.csv', chunksize=1000)\n",
    "type(chunker) # pandas.io.parsers.readers.TextFileReader\n",
    "\n",
    "# !!! here for Series we specifying the type\n",
    "tot = pd.Series([], dtype='int64')\n",
    "for piece in chunker:\n",
    "    # aggregate (tot.add) counts of key-values \n",
    "    tot = tot.add(piece[\"key\"].value_counts(), fill_value=0)\n",
    "tot = tot.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f76bd699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|something|a|b|c|d|message\n",
      "0|one|1|2|3.0|4|\n",
      "1|two|5|6||8|world\n",
      "2|three|9|10|11.0|12|foo\n",
      ",something,a,b,c,d,message\n",
      "0,one,1,2,3.0,4,NULL\n",
      "1,two,5,6,NULL,8,world\n",
      "2,three,9,10,11.0,12,foo\n",
      "one,1,2,3.0,4,\n",
      "two,5,6,,8,world\n",
      "three,9,10,11.0,12,foo\n",
      "a,d,c\n",
      "1,4,3.0\n",
      "5,8,\n",
      "9,12,11.0\n",
      "\n",
      "\n",
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['1', '2', '3']\n",
      "\n",
      "\n",
      "['a', 'b', 'c']\n",
      "['1', '2', '3']\n",
      "['1', '2', '3']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@ OUTPUT IN TEXT FORMAT @@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "data = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv')\n",
    "\"\"\"\n",
    " \tsomething \ta \tb \tc \td \tmessage\n",
    "0 \tone \t1 \t2 \t3.0 \t4 \tNaN\n",
    "1 \ttwo \t5 \t6 \tNaN \t8 \tworld\n",
    "2 \tthree \t9 \t10 \t11.0 \t12 \tfoo\"\"\"\n",
    "\n",
    "# write to file with comma\n",
    "data.to_csv('/home/vk/Python_Source/pydata-book/examples/out.csv')\n",
    "\n",
    "# display on the screen !!!\n",
    "\n",
    "d1 = data.to_csv(sys.stdout, sep=\"|\")\n",
    "\"\"\"\n",
    "|something|a|b|c|d|message\n",
    "0|one|1|2|3.0|4|\n",
    "1|two|5|6||8|world\n",
    "2|three|9|10|11.0|12|foo\n",
    "\"\"\"\n",
    "\n",
    "# filling empty values by NULL\n",
    "d2 = data.to_csv(sys.stdout, na_rep = \"NULL\")\n",
    "\"\"\"\n",
    "|something|a|b|c|d|message\n",
    "0|one|1|2|3.0|4|\n",
    "1|two|5|6||8|world\n",
    "2|three|9|10|11.0|12|foo\n",
    ",something,a,b,c,d,message\n",
    "0,one,1,2,3.0,4,NULL\n",
    "1,two,5,6,NULL,8,world\n",
    "2,three,9,10,11.0,12,foo\n",
    "\"\"\"\n",
    "\n",
    "# without markers\n",
    "d3 = data.to_csv(sys.stdout, index = False, header = False)\n",
    "\"\"\"\n",
    "one,1,2,3.0,4,\n",
    "two,5,6,,8,world\n",
    "three,9,10,11.0,12,foo\"\"\"\n",
    "\n",
    "# own colums name\n",
    "data.to_csv(sys.stdout, index = False, columns=[\"a\", \"d\", \"c\"])\n",
    "\"\"\"\n",
    "a,d,c\n",
    "1,4,3.0\n",
    "5,8,\n",
    "9,12,11.0\"\"\"\n",
    "\n",
    "# using standart Python in file with one delimeter\n",
    "import csv\n",
    "f = open('/home/vk/Python_Source/pydata-book/examples/ex7.csv')\n",
    "reader = csv.reader(f)\n",
    "print(\"\\n\")\n",
    "for line in reader:\n",
    "    print(line)\n",
    "\"\"\"\n",
    "['a', 'b', 'c']\n",
    "['1', '2', '3']\n",
    "['1', '2', '3']\"\"\"\n",
    "f.close()\n",
    "\n",
    "# fill dictionary by columns from file\n",
    "with open('/home/vk/Python_Source/pydata-book/examples/ex7.csv') as f:\n",
    "    lines = list(csv.reader(f))\n",
    "    header, values = lines[0], lines[1:]\n",
    "    \n",
    "    data_dict = {h: v for h, v in zip(header, zip(*values))}\n",
    "data_dict\n",
    "\"\"\"{'a': ('1', '1'), 'b': ('2', '2'), 'c': ('3', '3')}\"\"\"\n",
    "\n",
    "# using new format with own delimiter\n",
    "class my_dialect(csv.Dialect):\n",
    "    lineterminator = \"\\n\"\n",
    "    delimiter = \"#\"\n",
    "    quotechar = '\"'\n",
    "    quoting=csv.QUOTE_NONE\n",
    "\n",
    "f = open('/home/vk/Python_Source/pydata-book/examples/ex7.csv')\n",
    "#reader = csv.reader(f, dialect=my_dialect)\n",
    "reader = csv.reader(f, delimiter=',')\n",
    "print(\"\\n\")\n",
    "for line in reader:\n",
    "    print(line)\n",
    "f.close()\n",
    "\n",
    "with open('/home/vk/Python_Source/pydata-book/examples/mydata.csv', 'w') as f:\n",
    "    writer = csv.writer(f, dialect=my_dialect)\n",
    "    writer.writerow(('one', 'two', 'three'))\n",
    "    writer.writerow(('1', '2', '3'))\n",
    "    writer.writerow(('4', '5', '6'))\n",
    "    writer.writerow(('7', '8', '9'))\n",
    "\"\"\"\n",
    "one#two#three\n",
    "1#2#3\n",
    "4#5#6\n",
    "7#8#9\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8778ffd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_4305/1606306428.py:47: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  result = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex3.txt', sep = \"\\s+\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>something</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>two</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>three</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  something  a    b   c   d message\n",
       "0       one  1  2.0   3   4     NaN\n",
       "1       two  5  6.0       8   world\n",
       "2     three  9  NaN  11  12     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# first row from file is header,  indexes added auto\n",
    "df = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex1.csv')\n",
    "df\n",
    "\"\"\"\n",
    " \ta \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# file without header\n",
    "# var.1, column-indexing is auto\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex2.csv', header = None)\n",
    "\"\"\"\n",
    " \t0 \t1 \t2 \t3 \t4\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# var.2\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex2.csv', names = ['a', 'b', 'c', 'd', 'message'])\n",
    "\"\"\"\n",
    "a \tb \tc \td \t    message\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "names = ['a', 'b', 'c', 'd', 'message']\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex2.csv', names = names, index_col = 'message')\n",
    "\n",
    "# hierarchical index\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/csv_mindex.csv', index_col = ['key1', 'key2'])\n",
    "\"\"\"\n",
    "key1  key2 \t\t\n",
    "one \ta \t1 \t2\n",
    "        b \t3 \t4\n",
    "        c \t5 \t6\n",
    "        d \t7 \t8\n",
    "two \ta \t9 \t10\n",
    "        b \t11 \t12\n",
    "        c \t13 \t14\n",
    "        d \t15 \t16\"\"\"\n",
    "\n",
    "# file with spaces instead separator\n",
    "result = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex3.txt', sep = \"\\s+\")\n",
    "result\n",
    "\"\"\"\n",
    "            A        \tB       \tC\n",
    "aaa \t-0.264438 \t-1.026059 \t-0.619500\n",
    "bbb \t0.927272 \t0.302904 \t-0.032399\n",
    "ccc \t-0.264273 \t-0.386314 \t-0.217601\n",
    "ddd \t-0.871858 \t-0.348382 \t1.100491\"\"\"\n",
    "\n",
    "# skip 1,3,4 rows in file\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex4.csv', skiprows = [0, 2, 3])\n",
    "\"\"\"\n",
    " \ta \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# missing values\n",
    "# PANDAS get values 'NA', '-1.', '#IND', 'NULL' as missing values\n",
    "result = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv')\n",
    "\"\"\"\n",
    "something,a,b,c,d,message\n",
    "one,1,2,3,4,NA\n",
    "two,5,6,,8,world\n",
    "three,9,10,11,12,foo\"\"\"\n",
    "\n",
    "\"\"\"\n",
    " something \ta \tb \tc \td \tmessage\n",
    "0 \tone \t1 \t2 \t3.0 \t4 \tNaN\n",
    "1 \ttwo \t5 \t6 \tNaN \t8 \tworld\n",
    "2 \tthree \t9 \t10 \t11.0 \t12 \tfoo\"\"\"\n",
    "\n",
    "pd.isna(result)\n",
    "\"\"\"\n",
    " \tsomething \ta \tb \tc \td \tmessage\n",
    "0 \tFalse \tFalse \tFalse \tFalse \tFalse \tTrue\n",
    "1 \tFalse \tFalse \tFalse \tTrue \tFalse \tFalse\n",
    "2 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\"\"\"\n",
    "\n",
    "# result = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv', na_values = ['NULL']) hernja!!!\n",
    "\n",
    "# turn off processing of missing values\n",
    "results2 = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv',  keep_default_na = False)\n",
    "results2\n",
    "\"\"\"\n",
    " \tsomething \ta \tb \tc \td \tmessage\n",
    "0 \tone \t1 \t2 \t3 \t4 \tNA\n",
    "1 \ttwo \t5 \t6 \t\t8 \tworld\n",
    "2 \tthree \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "results2.isna()\n",
    "\"\"\"\n",
    "    something \ta \tb \t      c \td \t  message\n",
    "0 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "1 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "2 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\"\"\"\n",
    "\n",
    "# exchange only 'NA' char in file\n",
    "results3 = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv',\n",
    "                       keep_default_na=False, na_values = ['NA'])\n",
    "results3\n",
    "\"\"\"\n",
    "something \ta \tb \tc \td \tmessage\n",
    "0 \tone \t1 \t2 \t3 \t4 \tNaN\n",
    "1 \ttwo \t5 \t6 \t\t8 \tworld\n",
    "2 \tthree \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "results3.isna()\n",
    "\"\"\"\n",
    " \tsomething \ta \tb \tc \td \tmessage\n",
    "0 \tFalse \tFalse \tFalse \tFalse \tFalse \tTrue\n",
    "1 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\n",
    "2 \tFalse \tFalse \tFalse \tFalse \tFalse \tFalse\"\"\"\n",
    "\n",
    "# create own markers for exchange in the file\n",
    "sentinels = {'message':['foo', 'NA'], 'b': '10'}\n",
    "pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex5.csv', na_values=sentinels, keep_default_na=False)\n",
    "\"\"\"\n",
    " \tsomething \ta \tb \tc \td \tmessage\n",
    "0 \tone \t1 \t2.0 \t3 \t4 \tNaN\n",
    "1 \ttwo \t5 \t6.0 \t\t8 \tworld\n",
    "2 \tthree \t9 \tNaN \t11 \t12 \tNaN\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d5668b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}[{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12476/36975049.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  siblings = pd.DataFrame(result[\"glossary\"])[\"GlossDiv\"][1]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys as os\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@ JSON ########################\n",
    "\n",
    "obj = \"\"\"\n",
    "{\n",
    "    \"glossary\": {\n",
    "        \"title\": \"example glossary\",\n",
    "\t\t\"GlossDiv\": {\n",
    "            \"title\": \"S\",\n",
    "\t\t\t\"GlossList\": {\n",
    "                \"GlossEntry\": {\n",
    "                    \"ID\": \"SGML\",\n",
    "\t\t\t\t\t\"SortAs\": \"SGML\",\n",
    "\t\t\t\t\t\"GlossTerm\": \"Standard Generalized Markup Language\",\n",
    "\t\t\t\t\t\"Acronym\": \"SGML\",\n",
    "\t\t\t\t\t\"Abbrev\": \"ISO 8879:1986\",\n",
    "\t\t\t\t\t\"GlossDef\": {\n",
    "                        \"para\": \"A meta-markup language, used to create markup languages such as DocBook.\",\n",
    "\t\t\t\t\t\t\"GlossSeeAlso\": [\"GML\", \"XML\"]\n",
    "                    },\n",
    "\t\t\t\t\t\"GlossSee\": \"markup\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "# transform json to Python-object\n",
    "result = json.loads(obj)\n",
    "type(result)  # dict\n",
    "\n",
    "# transform Python-object to json\n",
    "asjson = json.dumps(result)\n",
    "asjson\n",
    "\n",
    "siblings = pd.DataFrame(result[\"glossary\"])[\"GlossDiv\"][1]\n",
    "siblings # dict\n",
    "\"\"\"\n",
    "{'GlossEntry': {'ID': 'SGML',\n",
    "  'SortAs': 'SGML',\n",
    "  'GlossTerm': 'Standard Generalized Markup Language',\n",
    "  'Acronym': 'SGML',\n",
    "  'Abbrev': 'ISO 8879:1986',\n",
    "  'GlossDef': {'para': 'A meta-markup language, used to create markup languages such as DocBook.',\n",
    "   'GlossSeeAlso': ['GML', 'XML']},\n",
    "  'GlossSee': 'markup'}}\"\"\"\n",
    "\n",
    "# json ---> DataFrame\n",
    "df = pd.read_json('/home/vk/Python_Source/pydata-book/examples/example.json')\n",
    "df\n",
    "\"\"\"\n",
    "    a \tb \tc\n",
    "0 \t1 \t2 \t3\n",
    "1 \t4 \t5 \t6\n",
    "2 \t7 \t8 \t9\"\"\"\n",
    "\n",
    "# DataFrame ---> json\n",
    "df.to_json(os.stdout) # {\"a\":{\"0\":1,\"1\":4,\"2\":7},\"b\":{\"0\":2,\"1\":5,\"2\":8},\"c\":{\"0\":3,\"1\":6,\"2\":9}}\n",
    "\n",
    "df.to_json(os.stdout, orient=\"records\") # [{\"a\":1,\"b\":2,\"c\":3},{\"a\":4,\"b\":5,\"c\":6},{\"a\":7,\"b\":8,\"c\":9}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7485a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INDICATOR_SEQ</th>\n",
       "      <th>PARENT_SEQ</th>\n",
       "      <th>AGENCY_NAME</th>\n",
       "      <th>INDICATOR_NAME</th>\n",
       "      <th>DESCRIPTION</th>\n",
       "      <th>PERIOD_YEAR</th>\n",
       "      <th>PERIOD_MONTH</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>FREQUENCY</th>\n",
       "      <th>DESIRED_CHANGE</th>\n",
       "      <th>INDICATOR_UNIT</th>\n",
       "      <th>DECIMAL_PLACES</th>\n",
       "      <th>YTD_TARGET</th>\n",
       "      <th>YTD_ACTUAL</th>\n",
       "      <th>MONTHLY_TARGET</th>\n",
       "      <th>MONTHLY_ACTUAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>On-Time Performance (West of Hudson)</td>\n",
       "      <td>Percent of commuter trains that arrive at thei...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>%</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.90</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>On-Time Performance (West of Hudson)</td>\n",
       "      <td>Percent of commuter trains that arrive at thei...</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>%</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>95.00</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>On-Time Performance (West of Hudson)</td>\n",
       "      <td>Percent of commuter trains that arrive at thei...</td>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>%</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.30</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>On-Time Performance (West of Hudson)</td>\n",
       "      <td>Percent of commuter trains that arrive at thei...</td>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>%</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.80</td>\n",
       "      <td>95.00</td>\n",
       "      <td>98.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Metro-North Railroad</td>\n",
       "      <td>On-Time Performance (West of Hudson)</td>\n",
       "      <td>Percent of commuter trains that arrive at thei...</td>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>Service Indicators</td>\n",
       "      <td>M</td>\n",
       "      <td>U</td>\n",
       "      <td>%</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "      <td>96.60</td>\n",
       "      <td>95.00</td>\n",
       "      <td>95.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INDICATOR_SEQ  PARENT_SEQ           AGENCY_NAME  \\\n",
       "0          28445         NaN  Metro-North Railroad   \n",
       "1          28445         NaN  Metro-North Railroad   \n",
       "2          28445         NaN  Metro-North Railroad   \n",
       "3          28445         NaN  Metro-North Railroad   \n",
       "4          28445         NaN  Metro-North Railroad   \n",
       "\n",
       "                         INDICATOR_NAME  \\\n",
       "0  On-Time Performance (West of Hudson)   \n",
       "1  On-Time Performance (West of Hudson)   \n",
       "2  On-Time Performance (West of Hudson)   \n",
       "3  On-Time Performance (West of Hudson)   \n",
       "4  On-Time Performance (West of Hudson)   \n",
       "\n",
       "                                         DESCRIPTION  PERIOD_YEAR  \\\n",
       "0  Percent of commuter trains that arrive at thei...         2008   \n",
       "1  Percent of commuter trains that arrive at thei...         2008   \n",
       "2  Percent of commuter trains that arrive at thei...         2008   \n",
       "3  Percent of commuter trains that arrive at thei...         2008   \n",
       "4  Percent of commuter trains that arrive at thei...         2008   \n",
       "\n",
       "   PERIOD_MONTH            CATEGORY FREQUENCY DESIRED_CHANGE INDICATOR_UNIT  \\\n",
       "0             1  Service Indicators         M              U              %   \n",
       "1             2  Service Indicators         M              U              %   \n",
       "2             3  Service Indicators         M              U              %   \n",
       "3             4  Service Indicators         M              U              %   \n",
       "4             5  Service Indicators         M              U              %   \n",
       "\n",
       "   DECIMAL_PLACES YTD_TARGET YTD_ACTUAL MONTHLY_TARGET MONTHLY_ACTUAL  \n",
       "0               1      95.00      96.90          95.00          96.90  \n",
       "1               1      95.00      96.00          95.00          95.00  \n",
       "2               1      95.00      96.30          95.00          96.90  \n",
       "3               1      95.00      96.80          95.00          98.30  \n",
       "4               1      95.00      96.60          95.00          95.80  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@@@@@@  XML and HTML @@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "tables = pd.read_html('/home/vk/Python_Source/pydata-book/examples/fdic_failed_bank_list.html')\n",
    "len(tables) # 1\n",
    "failure = tables[0] # DF type\n",
    "failure.head()\n",
    "failure[[\"Bank Name\", \"Closing Date\"]]\n",
    "\"\"\"\n",
    " \tBank Name \t                    Closing Date\n",
    "0 \tAllied Bank \t                September 23, 2016\n",
    "1 \tThe Woodbury Banking Company \tAugust 19, 2016\n",
    "2 \tFirst CornerStone Bank \t        May 6, 2016\n",
    "3 \tTrust Company Bank \t            April 29, 2016\n",
    "4 \tNorth Milwaukee State Bank \t    March 11, 201616, 2016\"\"\"\n",
    "\n",
    "close_timestamps = pd.to_datetime(failure[\"Closing Date\"])\n",
    "close_timestamps.dt.year.value_counts() # how many banks closed by year\n",
    "\n",
    "#@@@@@@ XML, library: lxml @@@@@@#\n",
    "\n",
    "# 1 var.\n",
    "from lxml import objectify\n",
    "path = \"/home/vk/Python_Source/pydata-book/datasets/mta_perf/Performance_MNR.xml\"\n",
    "with open(path) as f:\n",
    "    parsed = objectify.parse(f)\n",
    "root = parsed.getroot() # here root\n",
    "\n",
    "data = []\n",
    "skip_fields = [\"PARENT_SEQ\", \"INDICATOR_SEQ\", \"DESIRED_CHANGE\", \"DECIMAL_PLACES\"] # skip fields\n",
    "\n",
    "for elt in root.INDICATOR:\n",
    "    el_data = {}\n",
    "    for child in elt.getchildren():\n",
    "        if child.tag in skip_fields:\n",
    "            continue\n",
    "        el_data[child.tag] = child.pyval\n",
    "    data.append(el_data)\n",
    "    \n",
    "perf = pd.DataFrame(data)\n",
    "perf.head() # output first 5 rows\n",
    "\n",
    "# 2 var.\n",
    "perf2 = pd.read_xml(path)\n",
    "perf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82a2fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n   a \\tb \\tc \\td \\tmessage\\n0 \\t1 \\t2 \\t3 \\t4 \\thello\\n1 \\t5 \\t6 \\t7 \\t8 \\tworld\\n2 \\t9 \\t10 \\t11 \\t12 \\tfoo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@  BINARY FILE @@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "frame = pd.read_csv('/home/vk/Python_Source/pydata-book/examples/ex1.csv')\n",
    "frame\n",
    "\"\"\"\n",
    "   a \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "frame.to_pickle('/home/vk/Python_Source/pydata-book/examples/frame_pickle')\n",
    "pd.read_pickle('/home/vk/Python_Source/pydata-book/examples/frame_pickle')\n",
    "\"\"\"\n",
    "   a \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "#fec = pd.read_parquet(\"/home/vk/Python_Source/pydata-book/datasets/fec/fec.parquet\")\n",
    "#fec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe77833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4271/3361821313.py:36: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  frame.to_excel(writer, \"Sheet1\")\n",
      "/tmp/ipykernel_4271/3361821313.py:40: FutureWarning: Starting with pandas version 3.0 all arguments of to_excel except for the argument 'excel_writer' will be keyword-only.\n",
      "  frame.to_excel('/home/vk/Python_Source/pydata-book/examples/ex2.xlsx', \"Sheet2\")\n",
      "/tmp/ipykernel_4271/3361821313.py:89: FutureWarning: Starting with pandas version 3.0 all arguments of to_hdf except for the argument 'path_or_buf' will be keyword-only.\n",
      "  frame.to_hdf(path, \"obj3\", format=\"table\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.943016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.474442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.325922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a\n",
       "0  0.635294\n",
       "1  0.943016\n",
       "2  0.119151\n",
       "3  0.474442\n",
       "4 -2.325922"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#@@@@@@@@@@@@@@@@@@@@@@@  EXCEL @@@@@@@@@@@@@@@@@@@\n",
    "\n",
    "xlsx = pd.ExcelFile('/home/vk/Python_Source/pydata-book/examples/ex1.xlsx')\n",
    "xlsx.sheet_names # ['Sheet1']\n",
    "xlsx.parse(sheet_name=\"Sheet1\")\n",
    "\"\"\"\n",
    " \tUnnamed: 0 \ta \tb \tc \td \tmessage\n",
    "0 \t         0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t         1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t         2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# if there is indexing column in file\n",
    "xlsx.parse(sheet_name=\"Sheet1\", index_col=0)\n",
    "\"\"\"\n",
    "\n",
    "\ta \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# reading in DF\n",
    "frame = pd.read_excel('/home/vk/Python_Source/pydata-book/examples/ex1.xlsx', sheet_name=\"Sheet1\", index_col=0)\n",
    "frame\n",
    "\"\"\"\n",
    " \ta \tb \tc \td \tmessage\n",
    "0 \t1 \t2 \t3 \t4 \thello\n",
    "1 \t5 \t6 \t7 \t8 \tworld\n",
    "2 \t9 \t10 \t11 \t12 \tfoo\"\"\"\n",
    "\n",
    "# writing to excel\n",
    "# var.1\n",
    "writer = pd.ExcelWriter('/home/vk/Python_Source/pydata-book/examples/ex2.xlsx') # create object\n",
    "frame.to_excel(writer, \"Sheet1\")\n",
    "#writer.save()\n",
    "\n",
    "# var.2\n",
    "frame.to_excel('/home/vk/Python_Source/pydata-book/examples/ex2.xlsx', \"Sheet2\")\n",
    "\n",
    "#### HDFS ######\n",
    "path = '/home/vk/Python_Source/pydata-book/examples/mydata.h5'\n",
    "\n",
    "frame = pd.DataFrame({\"a\":np.random.standard_normal(100)})\n",
    "frame\n",
    "\"\"\"\n",
    " \ta\n",
    "0 \t-1.060651\n",
    "1 \t0.163633\n",
    "2 \t0.391957\n",
    "3 \t-0.974478\n",
    "4 \t0.458077\"\"\"\n",
    "\n",
    "store = pd.HDFStore(path) # save in HDFS file(empty)\n",
    "# 1.save data with HDFStore\n",
    "store[\"obj1\"] = frame\n",
    "store[\"obj1_col\"] = frame[\"a\"]\n",
    "store\n",
    "\"\"\"\n",
    "<class 'pandas.io.pytables.HDFStore'>\n",
    "File path: /home/vk/Python_Source/pydata-book/examples/mydata.h5\"\"\"\n",
    "\n",
    "# read file HDFS (as dictionary)\n",
    "store[\"obj1\"]\n",
    "\"\"\"\n",
    " \ta\n",
    "0 \t1.257156\n",
    "1 \t-1.410222\n",
    "2 \t1.227220\n",
    "3 \t-0.643782\n",
    "4 \t2.079251\"\"\"\n",
    "\n",
    "# 2.save data with put() with HDFStore\n",
    "# two schemas of store: 1-fixed and 2-table\n",
    "store.put(\"obj2\", frame, format=\"table\")\n",
    "store.select(\"obj2\", where = [\"index >=11 and index <= 15\"]) # !!! cool\n",
    "\"\"\"\n",
    "     a\n",
    "11 \t-0.540992\n",
    "12 \t-0.183081\n",
    "13 \t-0.558388\n",
    "14 \t-0.192218\n",
    "15 \t-1.085035\"\"\"\n",
    "\n",
    "store.close()\n",
    "\n",
    "# 3.save data with DF\n",
    "frame.to_hdf(path, \"obj3\", format=\"table\")\n",
    "# read\n",
    "pd.read_hdf(path, \"obj3\", where = [\"index < 5\"], mode='r+')\n",
    "\n",
    "#remove file\n",
    "#import os\n",
    "#os.remove(path)\n",
    "\n",
    "\"\"\"\n",
    "      a\n",
    "0 \t0.635294\n",
    "1 \t0.943016\n",
    "2 \t0.119151\n",
    "3 \t0.474442\n",
    "4 \t-2.325922\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7187617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoloto\n",
    "\n",
    "tables= pd.read_html('/home/vk/Downloads/arhiv_stoloto.html')\n",
    "df = tables[0]\n",
    "#df\n",
    "#tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc365749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>login</th>\n",
       "      <th>id</th>\n",
       "      <th>node_id</th>\n",
       "      <th>avatar_url</th>\n",
       "      <th>gravatar_id</th>\n",
       "      <th>url</th>\n",
       "      <th>html_url</th>\n",
       "      <th>followers_url</th>\n",
       "      <th>following_url</th>\n",
       "      <th>gists_url</th>\n",
       "      <th>starred_url</th>\n",
       "      <th>subscriptions_url</th>\n",
       "      <th>organizations_url</th>\n",
       "      <th>repos_url</th>\n",
       "      <th>events_url</th>\n",
       "      <th>received_events_url</th>\n",
       "      <th>type</th>\n",
       "      <th>user_view_type</th>\n",
       "      <th>site_admin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snitish</td>\n",
       "      <td>7503884</td>\n",
       "      <td>MDQ6VXNlcjc1MDM4ODQ=</td>\n",
       "      <td>https://avatars.githubusercontent.com/u/750388...</td>\n",
       "      <td></td>\n",
       "      <td>https://api.github.com/users/snitish</td>\n",
       "      <td>https://github.com/snitish</td>\n",
       "      <td>https://api.github.com/users/snitish/followers</td>\n",
       "      <td>https://api.github.com/users/snitish/following...</td>\n",
       "      <td>https://api.github.com/users/snitish/gists{/gi...</td>\n",
       "      <td>https://api.github.com/users/snitish/starred{/...</td>\n",
       "      <td>https://api.github.com/users/snitish/subscript...</td>\n",
       "      <td>https://api.github.com/users/snitish/orgs</td>\n",
       "      <td>https://api.github.com/users/snitish/repos</td>\n",
       "      <td>https://api.github.com/users/snitish/events{/p...</td>\n",
       "      <td>https://api.github.com/users/snitish/received_...</td>\n",
       "      <td>User</td>\n",
       "      <td>public</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     login       id               node_id  ...  type user_view_type site_admin\n",
       "0  snitish  7503884  MDQ6VXNlcjc1MDM4ODQ=  ...  User         public      False\n",
       "\n",
       "[1 rows x 19 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########  INTERECTION WITH HTML AND WEB API #############\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as rq\n",
    "\n",
    "url = \"https://api.github.com/repos/pandas-dev/pandas/issues\"\n",
    "resp = rq.get(url)\n",
    "resp.raise_for_status()\n",
    "data = resp.json()\n",
    "data[1][\"user\"] # block 1 node \"user\"\n",
    "\n",
    "issues = pd.DataFrame(data, columns=['number', 'user', 'title'])\n",
    "issues\n",
    "\"\"\"\n",
    "\tnumber \tuser \ttitle\n",
    "0 \t60752 \t{'login': 'snitish', 'id': 7503884, 'node_id':... \tENH: Support skipna parameter in GroupBy min, ...\n",
    "1 \t60750 \t{'login': 'sf-dcp', 'id': 144725249, 'node_id'... \tBUG: `pd.Series.isnumeric()` doesn't work on d...\n",
    "2 \t60748 \t{'login': 'gmcrocetti', 'id': 24530683, 'node_... \trefactor: deprecate usage of `cursor.execute` ...\n",
    "3 \t60747 \t{'login': 'agriyakhetarpal', 'id': 74401230, '... \tDOC: Reinstate the JupyterLite-based live shel...\n",
    "4 \t60744 \t{'login': 'kosiew', 'id': 29057562, 'node_id':... \tBUG: Ensure to_datetime raises errors for out-...\n",
    "5 \t60740 \t{'login': 'behrenhoff', 'id': 1408034, 'node_i... \tBUG: stack with future_stack=True and empty list\"\"\"\n",
    "\n",
    "logins = issues[\"user\"][:3]\n",
    "\"\"\"\n",
    "0    {'login': 'snitish', 'id': 7503884, 'node_id':...\n",
    "1    {'login': 'sf-dcp', 'id': 144725249, 'node_id'...\n",
    "2    {'login': 'gmcrocetti', 'id': 24530683, 'node_...\"\"\"\n",
    "\n",
    "logins[0][\"login\"] # snitish\n",
    "logins[0] # dictionary\n",
    "pd.DataFrame(logins[0], index = [0])\n",
    "\"\"\"\n",
    " \tlogin \t      id \t       node_id \t              avatar_url \t                                        gravatar_id \turl \thtml_url \tfollowers_url \tfollowing_url \tgists_url \tstarred_url \tsubscriptions_url \torganizations_url \trepos_url \tevents_url \treceived_events_url \ttype \tuser_view_type \tsite_admin\n",
    "0 \tsnitish \t7503884 \tMDQ6VXNlcjc1MDM4ODQ= \thttps://avatars.githubusercontent.com/u/750388... \t\thttps://api.github.com/users/snitish \thttps://github.com/snitish \thttps://api.github.com/users/snitish/followers \thttps://api.github.com/users/snitish/following... \thttps://api.github.com/users/snitish/gists{/gi... \thttps://api.github.com/users/snitish/starred{/... \thttps://api.github.com/users/snitish/subscript... \thttps://api.github.com/users/snitish/orgs \thttps://api.github.com/users/snitish/repos \thttps://api.github.com/users/snitish/events{/p... \thttps://api.github.com/users/snitish/received_... \tUser \tpublic \tFalse\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4fac9e2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "table test already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mcreate table test\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m(a varchar(20), b varchar(20),\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mc real, d integer );\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m con \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmydata.sqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m con\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtlanta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGeorgia\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;241m1.25\u001b[39m, \u001b[38;5;241m6\u001b[39m),\n\u001b[1;32m     15\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTallahassee\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFlorida\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m2.6\u001b[39m, \u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m     16\u001b[0m         (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSacramento\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1.7\u001b[39m, \u001b[38;5;241m5\u001b[39m)]\n",
      "\u001b[0;31mOperationalError\u001b[0m: table test already exists"
     ]
    }
   ],
   "source": [
    "############ WORKING WITH DATABASE ################\n",
    "import pandas as py\n",
    "import sqlite3\n",
    "\n",
    "query = \"\"\"\n",
    "create table test\n",
    "(a varchar(20), b varchar(20),\n",
    "c real, d integer );\"\"\"\n",
    "\n",
    "con = sqlite3.connect(\"mydata.sqlite\")\n",
    "con.execute(query)\n",
    "con.commit()\n",
    "\n",
    "data = [(\"Atlanta\", \"Georgia\",  1.25, 6),\n",
    "        (\"Tallahassee\", \"Florida\", 2.6, 3),\n",
    "        (\"Sacramento\", \"California\", 1.7, 5)]\n",
    "\n",
    "stmt = \"insert into test values (?, ?, ?, ?)\"\n",
    "con.executemany(stmt, data)\n",
    "con.commit()\n",
    "\n",
    "cursor = con.execute(\"select * from test\")\n",
    "rows = cursor.fetchall()\n",
    "print(rows)\n",
    "print(\"\\n\")\n",
    "\n",
    "# columns-name from cursor\n",
    "cursor.description\n",
    "\"\"\"\n",
    "(('a', None, None, None, None, None, None),\n",
    " ('b', None, None, None, None, None, None),\n",
    " ('c', None, None, None, None, None, None),\n",
    " ('d', None, None, None, None, None, None))\"\"\"\n",
    "\n",
    "pd.DataFrame(rows, columns = [row[0] for row in cursor.description])[:5]\n",
    "\"\"\"\n",
    "       a \t      b \t      c \td\n",
    "0 \tAtlanta \tGeorgia \t1.25 \t6\n",
    "1 \tTallahassee \tFlorida \t2.60 \t3\n",
    "2 \tSacramento \tCalifornia \t1.70 \t5\n",
    "3 \tAtlanta \tGeorgia \t1.25 \t6\n",
    "4 \tTallahassee \tFlorida \t2.60 \t3\"\"\"\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "cursor.close()\n",
    "con.close()\n",
    "################### POSTGRESQL ################################\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "dbConnectionUrl = psycopg2.connect(\"postgresql://vadim:1@localhost:5432/spark_labs\")\n",
    "\n",
    "stmt = \"insert into ch02(lname, fname, name) values(%s, %s, %s)\"\n",
    "\n",
    "with dbConnectionUrl.cursor() as curs:\n",
    "    curs.execute(stmt, (\"Jonh\", \"Wolker\", \"Jonh Wolker\"))\n",
    "    \n",
    "with dbConnectionUrl.cursor() as curs:\n",
    "    curs.execute(\"select * from ch02\")\n",
    "    rows_pg = curs.fetchall()\n",
    "    df = pd.DataFrame(rows_pg, columns = [row[0] for row in curs.description])[:5]\n",
    "\n",
    "print(df)\n",
    "dbConnectionUrl.close()\n",
    "\n",
    "#### SQLAlchemy ####\n",
    "import sqlalchemy as sqla\n",
    "\n",
    "db = sqla.create_engine(\"sqlite:///mydata.sqlite\")\n",
    "pd.read_sql(\"select * from test\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7ddaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d512f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
